{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww17020\viewh16980\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 COSC 343: Lab 2          Bayley Millar         ID:2940325\
\

\fs28 MACHINE LEARNING CONCEPTS\
\
1. I reckon that a AI that can learn for itself will be more effective that one that will need to be hard coded every time a  new problem occurs. For example a AI that was learning about its environment is going to better that one that needs to be hard coded every time.\
\
2.  In supervised learning, the agent learns a function from inputs to outputs. The learning algorithm receives a set of sample inputs with the associated outputs. The goal is that using the sample inputs the agent should be able to work out the problems by recognizing patterns.\
\
3. When it over fits it may not perform the task at hand, the agent might start thinking about the task too much causing unexpected output to occur. We can use curve fitting to compare the data to see what the hypothesis looks like. A easy way to reduce the possibility is to make the a consistent hypothesis which agrees with all the training examples. Choose the simplest hypothesis. Also you can ignore some of the test cases.\
\
PROBABILITY THEORY\
\
1.\
a: is a model of all the possible ways the world can be\
b: a random value that cannot be determined but may yet determine another variable\
c:  An event is any subset of points in a sample space\
d: the probability of one event happening if another event is to occur.\
e: A domains all possible values for the random variable, which returns probability for each possible value.\
\
2.(a)\
\
i: 4/12\
ii:3/6\
iii:2/6\
iv:2/9\
\
2.(b) 0.2177\
\
30 * 0.2177 = 6.531}